{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from keras.models import Sequential, load_model, Model \n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Input, BatchNormalization, Activation, add, MaxPooling1D, Cropping1D \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "#from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "#import hyperopt.fmin as hypfmin\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from math import ceil\n",
    "from Bio import SeqIO\n",
    "import warnings \n",
    "import datetime\n",
    "import keras.backend as kb\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import pybedtools as bt\n",
    "import h5py\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select protein coding or lncRNA transcripts, principal isoform if multiple (algorithm including apprisprincipal, ...\n",
    "    #tsl, level, use of alternative UTR, and trxtSize) \n",
    "def processGff(AgFn) :\n",
    "    GCDE = pd.read_csv(AgFn,sep='\\t',comment='#',header=None)\n",
    "    trxts = GCDE[GCDE[2]==\"transcript\"]\n",
    "    pcgBool=[bool(re.search('gene_type \\\"(?:protein_coding|.*l.*ncRNA)\\\";',s)) for s in trxts[8]]\n",
    "    trxts=trxts[pcgBool]\n",
    "    trxts['trx_name']=trxts.iloc[:,8].str.extract('transcript_name \\\"(.+?)\\\";')\n",
    "    trxts['gene']=trxts.iloc[:,8].str.extract('gene_name \\\"(.+?)\\\";')\n",
    "    princIso=[bool(re.search(\"appris_principal\",s)) for s in trxts[8]]\n",
    "    trxts=trxts[princIso]\n",
    "    trxts['tsl']=trxts.iloc[:,8].str.extract('transcript_support_level \\\"(.+?)\\\";')\n",
    "    trxts['level']=trxts.iloc[:,8].str.extract('; level (.+?);')\n",
    "    trxts['alt']=[bool(re.search('; tag \\\"(alternative_.*?)\\\";',s)) for s in trxts[8]]\n",
    "    trxts['trxSz']=trxts[4]-trxts[3]\n",
    "    trxts['tsl']=pd.to_numeric(trxts['tsl'], errors='coerce')\n",
    "    trxts['level']=pd.to_numeric(trxts['level'], errors='coerce')\n",
    "    splitGps = trxts.groupby('gene')\n",
    "    dups=pd.DataFrame()\n",
    "    trxts=pd.DataFrame()\n",
    "    for sg in splitGps:\n",
    "        sg=sg[1]\n",
    "        if len(sg) > 1:\n",
    "            sg=sg[sg['tsl'] == sg['tsl'].min()]\n",
    "            if len(sg) > 1:\n",
    "                sg=sg[sg['level'] == sg['level'].min()]\n",
    "                if len(sg) > 1:\n",
    "                    sg=sg[~sg['alt'].values]\n",
    "                    if len(sg) > 1:\n",
    "                        sg=sg[sg['trxSz'] == sg['trxSz'].max()]\n",
    "                        if len(sg) > 1:\n",
    "                            dups=dups.append(sg)\n",
    "                            continue \n",
    "        trxts=trxts.append(sg)\n",
    "    if len(dups) > 0:\n",
    "        print(\"{} Removed (Still has duplicates!!!)\".format(dups['trx_name']))\n",
    "        print(\"{} gene(s) with duplicates removed!!!\".format(len(set(dups['gene']))))\n",
    "    cols=list(range(0,9))+['trx_name','gene']\n",
    "    trxts=trxts.loc[:,cols]\n",
    "    return trxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExpressionSub(trxts,ExprTabFn):\n",
    "    Expr = pd.read_csv(ExprTabFn,sep='\\t',comment='#',header=None,usecols=[1,2,3,4],index_col =0)\n",
    "    SubExTrxs = Expr[Expr.mean(axis=1)>=1].index.values\n",
    "    trxts = trxts[trxts['gene'].isin(SubExTrxs)]\n",
    "    return trxts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any genes with pseudogenes\n",
    "def rmPseudoGns(tstTrxts,pgsFile):\n",
    "    pgs=pd.read_csv(pgsFile,comment='#')\n",
    "    pgs.dropna(inplace=True)\n",
    "    pgsNms=set(pgs['Human paralogue associated gene name'])\n",
    "    tstTrxts=tstTrxts[~tstTrxts.loc[:,'gene'].isin(pgsNms)]\n",
    "    return tstTrxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which chromosomes to subset from transcripts and corresponding features \n",
    "def subChroms(trxts,chrs):\n",
    "    chrs=['chr'+str(c) for c in chrs]\n",
    "    trxts=trxts[trxts[0].isin(chrs)].sort_values(0)\n",
    "    return trxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_AllRACs(trxts,InpMtrxs,sitesBedFn,multiclass=True):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros((2,trxtW)))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        InMx=np.array(InpMtrxs[r])\n",
    "        for ai in range(1,InMx.shape[1]-1):\n",
    "            if InMx[0,ai]==1:\n",
    "                if InMx[1,ai+1]==1:\n",
    "                    if InMx[0,ai-1]==1 or InMx[2,ai-1]==1:\n",
    "                        tgtMtx[0,ai]=0\n",
    "                        tgtMtx[2,ai]=1\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "            \n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "            if multiclass==False:\n",
    "                tgtMtx[2,sI]=0\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0],[0]]   \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_AllAs(trxts,InpMtrxs,sitesBedFn,multiclass=True):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros((2,trxtW)))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        if row[6] == '-' :\n",
    "            As=pd.Series(np.array(np.fliplr(InpMtrxs[r][0]))[0])\n",
    "        else:\n",
    "            As=pd.Series(np.array(InpMtrxs[r][0])[0])\n",
    "        Ais=As[As==1].index.values\n",
    "        for Ai in Ais:\n",
    "            tgtMtx[0,Ai]=0\n",
    "            tgtMtx[2,Ai]=1\n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "            if multiclass==False:\n",
    "                tgtMtx[2,sI]=0\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        InMx = np.array(InpMtrxs[r])\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0],[0]]   \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_Allnts(trxts,InpMtrxs,sitesBedFn):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros(trxtW))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        InMx = np.array(InpMtrxs[r])\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0]]   \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_AllYTGs_DNA(trxts,InpMtrxs,sitesBedFn,TrxtsGenomeFlank,multiclass=True):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    trxts=trxts.copy()\n",
    "    trxts[3]=trxts[3]-TrxtsGenomeFlank\n",
    "    trxts[4]=trxts[4]+TrxtsGenomeFlank\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros((2,trxtW)))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        InMx=np.array(InpMtrxs[r])\n",
    "        for ti in range(1,InMx.shape[1]-1):\n",
    "            if InMx[3,ti]==1:\n",
    "                if InMx[2,ti+1]==1:\n",
    "                    if InMx[3,ti-1]==1 or InMx[1,ti-1]==1:\n",
    "                        tgtMtx[0,ti]=0\n",
    "                        tgtMtx[2,ti]=1\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "            \n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "            if multiclass==False:\n",
    "                tgtMtx[2,sI]=0\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0],[0]]   \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_AllTs_DNA(trxts,InpMtrxs,sitesBedFn,TrxtsGenomeFlank,multiclass=True):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    trxts=trxts.copy()\n",
    "    trxts[3]=trxts[3]-TrxtsGenomeFlank\n",
    "    trxts[4]=trxts[4]+TrxtsGenomeFlank\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros((2,trxtW)))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        if row[6] == '-' :\n",
    "            Ts=pd.Series(np.array(np.fliplr(InpMtrxs[r][3]))[0])\n",
    "        else:\n",
    "            Ts=pd.Series(np.array(InpMtrxs[r][3])[0])\n",
    "        Tis=Ts[Ts==1].index.values\n",
    "        for Ti in Tis:\n",
    "            tgtMtx[0,Ti]=0\n",
    "            tgtMtx[2,Ti]=1\n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "            if multiclass==False:\n",
    "                tgtMtx[2,sI]=0\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        InMx = np.array(InpMtxs[r])\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0],[0]]   \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetMtxs_Allnts_DNA(trxts,InpMtxs,sitesBedFn,TrxtsGenomeFlank):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    tgtMtxs=[]\n",
    "    trxtsBt = bt.BedTool.from_dataframe(trxts.loc[:,list(range(0,8))+['trx_name']])\n",
    "    sites = bt.BedTool(sitesBedFn)\n",
    "    overlaps = trxtsBt.intersect(sites,wb=True,wa=True,s=True)\n",
    "    overlaps = overlaps.to_dataframe(sep='\\t',comment='#',header=None)\n",
    "    trxts=trxts.copy()\n",
    "    trxts[3]=trxts[3]-TrxtsGenomeFlank\n",
    "    trxts[4]=trxts[4]+TrxtsGenomeFlank\n",
    "    tgtMtxs=[]\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        ovs=overlaps[overlaps[8]==row['trx_name']][11]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        ons=np.matrix(np.ones(trxtW))\n",
    "        zs=np.matrix(np.zeros(trxtW))\n",
    "        tgtMtx=np.concatenate((ons,zs))\n",
    "        if len(ovs) == 0:\n",
    "            tgtMtxs.append(tgtMtx)\n",
    "            continue\n",
    "        siteIndx= ovs-row[3]\n",
    "        for sI in siteIndx:\n",
    "            tgtMtx[0,sI]=0\n",
    "            tgtMtx[1,sI]=1\n",
    "        if row[6] == '-' :\n",
    "            tgtMtx = np.fliplr(tgtMtx)\n",
    "        InMx = np.array(InpMtxs[r])\n",
    "        Nis = [Ni for Ni in range(InMx.shape[1]) if (InMx[:,Ni] == [[0],[0],[0],[0]]).all()]\n",
    "        if len(Nis)>0:\n",
    "            for Ni in Nis:\n",
    "                tgtMtx[:,Ni]=[[0],[0]]  \n",
    "        tgtMtxs.append(tgtMtx)\n",
    "    return tgtMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target blocks in size I blocks \n",
    "def getTargetBlocks(tgtMtxs):\n",
    "    tgtBlocks=[]\n",
    "    for tgtMtx in tgtMtxs:\n",
    "        numBlocks = ceil(len(tgtMtx.T)/5000)\n",
    "        blW = numBlocks * 5000\n",
    "        bAdd = blW - len(tgtMtx.T) \n",
    "        tgtMtxZpd = np.pad(tgtMtx,((0,0),(0,bAdd)),'constant')\n",
    "        for bln in range(numBlocks):\n",
    "            blLow = 5000*(bln) \n",
    "            blHigh = 5000*(bln+1) # - 1 in blHigh is omitted  \n",
    "            block = tgtMtxZpd[:,blLow:blHigh]\n",
    "            tgtBlocks.append(block)\n",
    "    return tgtBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transcript sequences into one-hot encoded form \n",
    "def getInputMtxs(genomeFasta,trxts):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    fasta_sequences = SeqIO.parse(open(genomeFasta),'fasta')\n",
    "    seqs={}\n",
    "    for seq in fasta_sequences:\n",
    "        if seq.name[:3]=='chr':\n",
    "            seqs[seq.name]=seq  \n",
    "    trnMtxs=[]\n",
    "    posBases=dict(zip(['A','C','G','T'],range(4)))\n",
    "    negBases=dict(zip(['T','G','C','A'],range(4)))\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        trxtSeq=seqs[row[0]].seq[row[3]-1:row[4]]\n",
    "        trnMtx = np.matrix(np.zeros((4,trxtW)))\n",
    "        if row[6] == '+':\n",
    "            for bi in range(trxtW):\n",
    "                try:\n",
    "                    b = trxtSeq[bi]\n",
    "                    trnMtx[posBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "        else:\n",
    "            for bi in range(trxtW):        \n",
    "                try:\n",
    "                    b = trxtSeq[bi]            \n",
    "                    trnMtx[negBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "            trnMtx = np.fliplr(trnMtx)\n",
    "        trnMtxs.append(trnMtx)\n",
    "    return trnMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transcript sequences into one-hot encoded form \n",
    "def getInputMtxs_DNA(genomeFasta,trxts,TrxtsGenomeFlank):\n",
    "    fasta_sequences = SeqIO.parse(open(genomeFasta),'fasta')\n",
    "    seqs={}\n",
    "    for seq in fasta_sequences:\n",
    "        if seq.name[:3]=='chr':\n",
    "            seqs[seq.name]=seq  \n",
    "    trxts=trxts.copy()\n",
    "    trxts[3]=trxts[3]-TrxtsGenomeFlank\n",
    "    trxts[4]=trxts[4]+TrxtsGenomeFlank\n",
    "    trnMtxs=[]\n",
    "    negBases=dict(zip(['A','C','G','T'],range(4)))\n",
    "    posBases=dict(zip(['T','G','C','A'],range(4)))\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        trxtW=row[4]-row[3]+1\n",
    "        trxtSeq=seqs[row[0]].seq[row[3]-1:row[4]]\n",
    "        trnMtx = np.matrix(np.zeros((4,trxtW)))\n",
    "        if row[6] == '+':\n",
    "            for bi in range(trxtW):\n",
    "                try:\n",
    "                    b = trxtSeq[bi]\n",
    "                    trnMtx[posBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "        else:\n",
    "            for bi in range(trxtW):        \n",
    "                try:\n",
    "                    b = trxtSeq[bi]            \n",
    "                    trnMtx[negBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "            trnMtx = np.fliplr(trnMtx)\n",
    "        trnMtxs.append(trnMtx)\n",
    "    return trnMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S/2 + I + S/2 sized blocks to feed into model where S is overall size of flank and I is sequences to predict status \n",
    "def getInputBlocks(trnMtxs,flankL):\n",
    "    trnBlocks=[]\n",
    "    halfFlankL=int(flankL/2)\n",
    "    for trnMtx in trnMtxs:\n",
    "        numBlocks = ceil(len(trnMtx.T)/5000)\n",
    "        blW = numBlocks * 5000\n",
    "        bAdd = blW - len(trnMtx.T) \n",
    "        rightPad=int(halfFlankL + bAdd)\n",
    "        trnMtxZpd = np.pad(trnMtx,((0,0),(halfFlankL,rightPad)),'constant')\n",
    "        for bln in range(numBlocks):\n",
    "            blLow = 5000*(bln) \n",
    "            blHigh = 5000*(bln+1) + flankL # - 1 in blHigh is omitted  \n",
    "            block = trnMtxZpd[:,blLow:blHigh]\n",
    "            trnBlocks.append(block)\n",
    "    return trnBlocks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mtxs_toH5Blocks(InpMtxs,TgtMtxs,flankL,CHUNK_SIZE,train_or_test):\n",
    "    num_CHUNKS=ceil(len(InpMtxs)/CHUNK_SIZE)\n",
    "    h5f_Inp=h5py.File('Inp_'+train_or_test+'.h5', 'w')\n",
    "    h5f_Tgt=h5py.File('Tgt_'+train_or_test+'.h5', 'w')\n",
    "    for i in range(num_CHUNKS):\n",
    "        Ib=getInputBlocks(InpMtxs[CHUNK_SIZE*i:CHUNK_SIZE*(i+1)],flankL)\n",
    "        Tb=getTargetBlocks(TgtMtxs[CHUNK_SIZE*i:CHUNK_SIZE*(i+1)])\n",
    "        h5f_Inp[str(i)]=np.swapaxes(np.stack(Ib,axis=1).T,0,1).astype('int8')\n",
    "        h5f_Tgt[str(i)]=np.swapaxes(np.stack(Tb,axis=1).T,0,1).astype('int8')\n",
    "    print ('Inp_'+train_or_test+'.h5'+'and'+'Tgt_'+train_or_test+'.h5'+'created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create multiple resnet layers in model \n",
    "def resnet(x,fltrNumb,fltrW,dilr,numbRns):\n",
    "    def oneLoop(x):\n",
    "        z = BatchNormalization()(x)\n",
    "        z = Activation('relu')(z)\n",
    "        z = Conv1D(fltrNumb,kernel_size=(fltrW,),dilation_rate=dilr,padding='same')(z)\n",
    "        return z\n",
    "    full=x\n",
    "    for n in range(numbRns):\n",
    "        z=oneLoop(full)\n",
    "        z=oneLoop(z)\n",
    "        full = add([full,z]) \n",
    "    return full   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard categorical cross entropy for sequence outputs\n",
    "def categorical_crossentropy_2d_3ctgs(y_true, y_pred):\n",
    "    return - kb.mean(y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10)\n",
    "                   + y_true[:, :, 2]*kb.log(y_pred[:, :, 2]+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy_2d_2ctgs(y_true, y_pred):\n",
    "    return - kb.mean(y_true[:, :, 0]*kb.log(y_pred[:, :, 0]+1e-10)\n",
    "                   + y_true[:, :, 1]*kb.log(y_pred[:, :, 1]+1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard categorical cross entropy for sequence outputs\n",
    "def categorical_crossentropy_2d(y_true, y_pred, numOut_Classes=3):\n",
    "    loss=0\n",
    "    for i in range(numOut_Classes):\n",
    "        loss = loss + y_true[:, :, i]*kb.log(y_pred[:, :, i]+1e-10)\n",
    "    return - kb.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parallel(model, gpu_count):\n",
    "\n",
    "    def get_slice(data, idx, parts):\n",
    "\n",
    "        shape = tf.shape(data)\n",
    "        stride = tf.concat([shape[:1]//parts, shape[1:]*0], 0)\n",
    "        start = stride * idx\n",
    "\n",
    "        size = tf.concat([shape[:1]//parts, shape[1:]], 0) \n",
    "        # Split the batch into equal parts \n",
    "\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                # Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape,\n",
    "                                  arguments={'idx': i, 'parts': gpu_count})(x)\n",
    "                    inputs.append(slice_n)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                # Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # Merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(concatenate(outputs, axis=0))\n",
    "            \n",
    "        return Model(inputs=model.inputs, outputs=merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topK_auPRC(model,Inp,Tgt,numOut_Classes):\n",
    "    p=model.predict(Inp)\n",
    "    Tks=[]\n",
    "    PRs=[]\n",
    "    for c in range(1,numOut_Classes):\n",
    "        Fullc=Tgt[:,:,c].flatten()\n",
    "        S=[i for i in range(len(Fullc)) if Fullc[i] == 1]\n",
    "        pS=np.argsort(p[:,:,c].flatten())[-len(S):]\n",
    "        pS=pd.Series(pS)\n",
    "        nCrct=pS[pS.isin(S)].size\n",
    "        Tk=nCrct/float(len(S))\n",
    "        Tks.append(Tk)\n",
    "        PR=average_precision_score(Fullc,p[:,:,c].flatten())\n",
    "        PRs.append(PR)\n",
    "    if numOut_Classes < 3:\n",
    "        Tks.append(0.0)\n",
    "        PRs.append(0.0)\n",
    "    return(Tks[0],Tks[1],PRs[0],PRs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
