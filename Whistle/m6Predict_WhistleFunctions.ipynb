{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from keras.models import Sequential, load_model, Model \n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Input, BatchNormalization, Activation, add, MaxPooling1D, Cropping1D \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "#from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "#import hyperopt.fmin as hypfmin\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from math import ceil\n",
    "from Bio import SeqIO\n",
    "import warnings \n",
    "import datetime\n",
    "import keras.backend as kb\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import pybedtools as bt\n",
    "import h5py\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transcript sequences into one-hot encoded form \n",
    "def getInputMtxs_DNA(genomeFasta,m6ASites,TrxtsGenomeFlank):\n",
    "    fasta_sequences = SeqIO.parse(open(genomeFasta),'fasta')\n",
    "    seqs={}\n",
    "    for seq in fasta_sequences:\n",
    "        if seq.name[:3]=='chr':\n",
    "            seqs[seq.name]=seq  \n",
    "    trxts=pd.read_csv(m6ASites,sep='\\t',comment='#',header=None,skiprows=1)\n",
    "    trxts=trxts.copy()\n",
    "    avg=((trxts[2]+trxts[3])/2).astype('int32')\n",
    "    trxts[2]=(avg-TrxtsGenomeFlank)\n",
    "    trxts[3]=(avg+TrxtsGenomeFlank)\n",
    "    trnMtxs=[]\n",
    "    negBases=dict(zip(['A','C','G','T'],range(4)))\n",
    "    posBases=dict(zip(['T','G','C','A'],range(4)))\n",
    "    for r in range(len(trxts)):\n",
    "        row=trxts.iloc[r,:]\n",
    "        trxtW=row[3]-row[2]+1\n",
    "        trxtSeq=seqs[row[0]].seq[row[2]-1:row[3]]\n",
    "        trnMtx = np.matrix(np.zeros((4,trxtW)))\n",
    "        if row[1] == '+':\n",
    "            for bi in range(trxtW):\n",
    "                try:\n",
    "                    b = trxtSeq[bi]\n",
    "                    trnMtx[posBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "        else:\n",
    "            for bi in range(trxtW):        \n",
    "                try:\n",
    "                    b = trxtSeq[bi]            \n",
    "                    trnMtx[negBases[b],bi] = 1\n",
    "                except:\n",
    "                    continue \n",
    "            trnMtx = np.fliplr(trnMtx)\n",
    "        trnMtxs.append(trnMtx)\n",
    "    return trnMtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randSubBlocks(InpBlocks,TgtBlocks):\n",
    "    InpBlocks, TgtBlocks = pd.Series(InpBlocks), pd.Series(TgtBlocks)\n",
    "    rand = np.random.permutation(len(InpBlocks))\n",
    "    InpBlocks = list(InpBlocks.iloc[rand])\n",
    "    TgtBlocks = list(TgtBlocks.iloc[rand])\n",
    "    return InpBlocks,TgtBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mtxs_toH5Blocks(InpMtxs,TgtMtxs,CHUNK_SIZE,train_or_test):\n",
    "    num_CHUNKS=ceil(len(InpMtxs)/CHUNK_SIZE)\n",
    "    h5f_Inp=h5py.File('Inp_'+train_or_test+'.h5', 'w')\n",
    "    h5f_Tgt=h5py.File('Tgt_'+train_or_test+'.h5', 'w')\n",
    "    for i in range(num_CHUNKS):\n",
    "        Ib=InpMtxs[CHUNK_SIZE*i:CHUNK_SIZE*(i+1)]\n",
    "        Tb=TgtMtxs[CHUNK_SIZE*i:CHUNK_SIZE*(i+1)]\n",
    "        h5f_Inp[str(i)]=np.swapaxes(np.stack(np.array(Ib),axis=1).T,0,1).astype('int8')\n",
    "        h5f_Tgt[str(i)]=np.expand_dims(np.expand_dims(np.array(Tb),1),2).astype('int8')\n",
    "    print ('Inp_'+train_or_test+'.h5'+'and'+'Tgt_'+train_or_test+'.h5'+'created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create multiple resnet layers in model \n",
    "def resnet(x,fltrNumb,fltrW,dilr,numbRns):\n",
    "    def oneLoop(x):\n",
    "        z = BatchNormalization()(x)\n",
    "        z = Activation('relu')(z)\n",
    "        z = Conv1D(fltrNumb,kernel_size=(fltrW,),dilation_rate=dilr,padding='same')(z)\n",
    "        return z\n",
    "    full=x\n",
    "    for n in range(numbRns):\n",
    "        z=oneLoop(full)\n",
    "        z=oneLoop(z)\n",
    "        full = add([full,z]) \n",
    "    return full   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parallel(model, gpu_count):\n",
    "\n",
    "    def get_slice(data, idx, parts):\n",
    "\n",
    "        shape = tf.shape(data)\n",
    "        stride = tf.concat([shape[:1]//parts, shape[1:]*0], 0)\n",
    "        start = stride * idx\n",
    "\n",
    "        size = tf.concat([shape[:1]//parts, shape[1:]], 0) \n",
    "        # Split the batch into equal parts \n",
    "\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    # Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                # Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape,\n",
    "                                  arguments={'idx': i, 'parts': gpu_count})(x)\n",
    "                    inputs.append(slice_n)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                # Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # Merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(concatenate(outputs, axis=0))\n",
    "            \n",
    "        return Model(inputs=model.inputs, outputs=merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topK_auPRC(model,Inp,Tgt,numOut_Classes):\n",
    "    p=model.predict(Inp)\n",
    "    Tks=[]\n",
    "    PRs=[]\n",
    "    if numOut_Classes > 1:\n",
    "        cRange=range(1,numOut_Classes)\n",
    "    else:\n",
    "        cRange=[0]\n",
    "    for c in cRange:\n",
    "        Fullc=Tgt[:,:,c].flatten()\n",
    "        S=[i for i in range(len(Fullc)) if Fullc[i] == 1]\n",
    "        pS=np.argsort(p[:,:,c].flatten())[-len(S):]\n",
    "        pS=pd.Series(pS)\n",
    "        nCrct=pS[pS.isin(S)].size\n",
    "        Tk=nCrct/float(len(S))\n",
    "        Tks.append(Tk)\n",
    "        PR=average_precision_score(Fullc,p[:,:,c].flatten())\n",
    "        PRs.append(PR)\n",
    "    if numOut_Classes < 3:\n",
    "        Tks.append(0.0)\n",
    "        PRs.append(0.0)\n",
    "    return(Tks[0],Tks[1],PRs[0],PRs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
